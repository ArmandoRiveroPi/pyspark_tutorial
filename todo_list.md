- [x] start and configure Spark
- [x] load data from the files
- [x] prepare data for classification models
    - [x] explore the data without knowing distributions
        - [x] explore factors
        - [x] explore numeric cols
    - [x] standardize and clean the data
        - [x] strip dots out of income column
        - [x] strip spaces out of string columns
    - [x] string index the factor columns
    - [x] one-hot encode the indexed factor columns
    - [x] build dataframe with features vector and labels column
- [x] fit a simple classification model
    - [x] prepare the data frame by applying all transformations 
    (cleaning, encoding, etc)        
- [x] obtain evaluation metrics for a single model
- [x] fit and compare several classification models without tuning
    - [x] create an object container for the models
    - [x] initialize the models with default hyperparameters
    - [x] fit and compare the results with the evaluator
- [ ] **fit and compare several classification models with tuning and crossvalidation**
    - [ ] be able to pass a list of hyperparameters values for each hyperparameter
    - [ ] tune and obtain the best hyperparam set per model
    - [ ] compare the tuned models with the evaluator
- [ ] prepare data for regression
- [ ] fit regression model(s)
- [ ] obtain the regression metrics and compare the models
- [ ] improve README.md